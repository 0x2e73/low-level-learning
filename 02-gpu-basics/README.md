# Phase 2: GPU Basics

**Status:** âšª Not Started  
**Target Duration:** 8-12 weeks

## Learning Objectives

Understanding parallel computing on GPUs:
- [ ] Thread/Block/Grid hierarchy
- [ ] Shared memory and synchronization
- [ ] Memory coalescing
- [ ] Occupancy and performance metrics
- [ ] Write optimized CUDA kernels

## Resources

### Primary
- [ ] "Programming Massively Parallel Processors" (Kirk & Hwu) - Chapters 1-7
- [ ] CUDA C Programming Guide

### Practice
- [ ] NVIDIA CUDA samples
- [ ] GPU performance optimization tutorials

## Kernels to Implement

### Basics
- [ ] Vector addition
- [ ] Dot product
- [ ] Matrix transpose

### Intermediate
- [ ] Matrix multiplication (naive)
- [ ] Matrix multiplication (tiled/shared memory)
- [ ] Reduction (sum, max)

### Advanced
- [ ] Convolution
- [ ] Prefix sum (scan)
- [ ] Custom optimization challenge

## ðŸ“Š Performance Goals

Track speedups vs CPU:
- Vector add: ?x
- MatMul naive: ?x
- MatMul optimized: ?x

---
*To be started after Phase 1*
